{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import external tools:\n",
    "import time \n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "from datetime import datetime\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# I am running this script on two different computers, so i need to change paths\n",
    "# depending on computer in use: \n",
    "if getpass.getuser()==\"joanna.luberadzka\":\n",
    "    projectdir=\"/Users/joanna.luberadzka/Documents/VAE-IR/\"\n",
    "    datadir=\"/Users/joanna.luberadzka/Documents/Data/IR_Arni_upload_numClosed_0-5/\"\n",
    "elif getpass.getuser()==\"ubuntu\":\n",
    "    projectdir=\"/home/ubuntu/joanna/VAE-IR/\"\n",
    "    datadir=\"/home/ubuntu/Data/IR_Arni_upload_numClosed_0-5/\"\n",
    "\n",
    "# Add path of this project\n",
    "sys.path.insert(0, projectdir+'src/')\n",
    "\n",
    "# Import and automatically reload my own modules:\n",
    "import models; importlib.reload(models)\n",
    "import train; importlib.reload(train)\n",
    "import datasetprep as dsprep; importlib.reload(dsprep)\n",
    "import helpers; importlib.reload(helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created a table summarizing two IR data bases (Arni and BUT)\n",
    "# Table contains file path, and acoustic parameters: rt,drr,cte,edt (computed using matlab toolbox)\n",
    "\n",
    "# -- Data: --\n",
    "if getpass.getuser()==\"joanna.luberadzka\":\n",
    "    INFO_FILE = projectdir + \"irstats_ARNIandBUT_local.csv\"\n",
    "elif getpass.getuser()==\"ubuntu\":\n",
    "    INFO_FILE = projectdir+\"irstats_ARNIandBUT_datura.csv\"\n",
    "\n",
    "IrData = pd.read_csv(INFO_FILE,delimiter=',')\n",
    "IrData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each entry of that database represents one recorded room impulse response. \n",
    "# Below, I plot a random sample from the database and print its acoustic parameters computed with a Matlab toolbox.\n",
    "\n",
    "rand_ir_idx=random.sample(range(len(IrData)),1)[0]\n",
    "# get info of an impulse response with a specific index\n",
    "print(f\"The filename of RIR sample {rand_ir_idx} is: \"+ IrData[\"filepath\"][rand_ir_idx])\n",
    "print(\"The reverberation time is: rt= \"+ str(IrData[\"rt\"][rand_ir_idx]))\n",
    "print(\"The direct-to-reverberant ratio is: drr= \"+ str(IrData[\"drr\"][rand_ir_idx]))\n",
    "print(\"The early-to-late reflections ratio is: cte= \"+ str(IrData[\"cte\"][rand_ir_idx]))\n",
    "print(\"The early decay time is: edt= \"+ str(IrData[\"drr\"][rand_ir_idx]))\n",
    "\n",
    "# get rir waveform and spectrum\n",
    "h,H,_= helpers.wav2powspec(IrData[\"filepath\"][rand_ir_idx])\n",
    "\n",
    "# plot waveform and spectrogram\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.subplot (1,2,1)\n",
    "plt.imshow(librosa.power_to_db(H), origin=\"lower\", aspect=\"auto\")\n",
    "plt.title(f'Log-spectrogram of RIR sample {rand_ir_idx}')\n",
    "plt.subplot (1,2,2)\n",
    "plt.plot(h)\n",
    "plt.title(f'Waveform of RIR sample {rand_ir_idx}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the scatterplots below each point represents one impulse response. I plotted rt as a function of drr and add a colormap \n",
    "# to represent additional information about each ir (which database, cte, edt). \n",
    "\n",
    "# plot parameters of impulse responses in the data  \n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=IrData[\"rt\"][0:11331], y=IrData[\"drr\"][0:11331],label=\"Arni\", alpha=0.2)\n",
    "ax.scatter(x=IrData[\"rt\"][11331:], y=IrData[\"drr\"][11331:],label=\"BUT\",alpha=0.2)\n",
    "plt.xlabel(\"T60\")\n",
    "plt.ylabel(\"DRR\")\n",
    "plt.legend()\n",
    "ax.set(title=\"Colormap: Two IR data bases\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=IrData[\"rt\"], y=IrData[\"drr\"],c=IrData[\"cte\"], alpha=0.2)\n",
    "sc1=plt.xlabel(\"T60\")\n",
    "sc2=plt.ylabel(\"DRR\")\n",
    "ax.set(title=\"Colormap: Early to late reflections (CTE) \")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=IrData[\"rt\"], y=IrData[\"drr\"],c=IrData[\"edt\"], alpha=0.2)\n",
    "plt.xlabel(\"T60\")\n",
    "plt.ylabel(\"DRR\")\n",
    "ax.set(title=\"Colormap: Early decay time (EDT)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to use the IR database and train an autoencoder to learn the transformation between the \n",
    "# input impulse response and a lower-dimensional embedding space. \n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "# ----- DATA: -----\n",
    "if getpass.getuser()==\"joanna.luberadzka\":\n",
    "    INFO_FILE = projectdir + \"irstats_ARNIandBUT_datura.csv\"\n",
    "elif getpass.getuser()==\"ubuntu\":\n",
    "    INFO_FILE = projectdir+\"irstats_ARNIandBUT_datura.csv\"\n",
    "\n",
    "# Create dataset object\n",
    "SAMPLING_RATE=8e3\n",
    "PREPROC=\"powspec\"\n",
    "dataset = dsprep.DatasetRirs(INFO_FILE,SAMPLING_RATE,PREPROC)\n",
    "\n",
    "\n",
    "# how much data should be used from the data base\n",
    "perc_data_use=1\n",
    "N_used = round(len(dataset) * perc_data_use)\n",
    "N_unused = len(dataset) - N_used\n",
    "usedset, unusedset = random_split(dataset, [N_used, N_unused])\n",
    "# how much training data \n",
    "N_train = round(len(usedset) * 0.8)\n",
    "N_rest = len(usedset) - N_train\n",
    "trainset, restset = random_split(usedset, [N_train, N_rest])\n",
    "# how much test and validation data \n",
    "N_test = round(len(restset) * 0.5)\n",
    "N_val = len(restset) - N_test\n",
    "testset, valset = random_split(restset, [N_test, N_val])\n",
    "\n",
    "# create dataloaders\n",
    "BATCH_SIZE=16\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=6,pin_memory=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=True, num_workers=6,pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True, num_workers=6,pin_memory=True)\n",
    "\n",
    "# ----- MODEL: -----\n",
    "# model=models.Conv1D_VAE(x_len=24000,h_len=256,z_len=24).to(DEVICE)\n",
    "model=models.AutoencoderConv(z_len=24).to(DEVICE)\n",
    "\n",
    "# -- Training: --\n",
    "LEARNRATE=1e-3\n",
    "N_EPOCHS=10\n",
    "trainparams={\n",
    "\"num_epochs\": N_EPOCHS, \n",
    "\"device\": DEVICE,\n",
    "\"learnrate\":LEARNRATE,\n",
    "\"optimizer\": torch.optim.Adam(model.parameters(), LEARNRATE),\n",
    "\"criterion\": nn.MSELoss()}\n",
    "\n",
    "# training\n",
    "start = time.time()\n",
    "outputs_evol, loss_evol=train.training(model, trainloader, valloader, trainparams, 1)\n",
    "end=time.time()\n",
    "now=datetime.now(); dt_string = now.strftime(\"%d-%m-%Y--%H-%M\")\n",
    "print(f\"training time: {(end-start)}\" ) \n",
    "torch.save(model.state_dict(), projectdir + \"models/trained_model_\"+dt_string+\".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training report\n",
    "report = {\n",
    "    'model'      : str(model),\n",
    "    'preproc'    : PREPROC,\n",
    "    'sr'         : SAMPLING_RATE,\n",
    "    'start_time' : start,\n",
    "    'end_time'   : end,\n",
    "    'loss_evol'  : loss_evol,\n",
    "    'n_epochs'   : N_EPOCHS,\n",
    "    'learnrate'  : LEARNRATE,\n",
    "    'batch_size' : BATCH_SIZE,\n",
    "    'data_used'  : perc_data_use\n",
    "    }\n",
    "\n",
    "# the json file where the output must be stored\n",
    "import json\n",
    "out_file = open(f\"{projectdir}models/train_report_{dt_string}_.json\", \"w\")\n",
    "json.dump(report, out_file, indent = None)\n",
    "out_file.close()\n",
    "\n",
    "loss_evol_unziped=list(zip(*loss_evol))\n",
    "plt.figure(figsize=(6, 6))\n",
    "train_loss=loss_evol_unziped[0][1:]\n",
    "val_loss=loss_evol_unziped[1][1:]\n",
    "plt.plot(train_loss,label=\"training loss\")\n",
    "plt.plot(val_loss,label=\"validation loss\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce963d0b11d3bbec7fb5cbe3b3e5eb22455c53ff6b457d89286ef32149820fa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
