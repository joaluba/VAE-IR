{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import external tools:\n",
    "import time \n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# I am running this script on two different computers, so i need to change paths\n",
    "# depending on computer in use: \n",
    "if getpass.getuser()==\"joanna.luberadzka\":\n",
    "    projectdir=\"/Users/joanna.luberadzka/Documents/VAE-IR/\"\n",
    "    datadir=\"/Users/joanna.luberadzka/Documents/Data/IR_Arni_upload_numClosed_0-5/\"\n",
    "elif getpass.getuser()==\"ubuntu\":\n",
    "    projectdir=\"/home/ubuntu/joanna/VAE-IR/\"\n",
    "    datadir=\"/home/ubuntu/Data/IR_Arni_upload_numClosed_0-5/\"\n",
    "\n",
    "# Add path of this project\n",
    "sys.path.insert(0, projectdir+'src/')\n",
    "\n",
    "# Import and automatically reload my own modules:\n",
    "import models; importlib.reload(models)\n",
    "import train; importlib.reload(train)\n",
    "import datasetprep as dsprep; importlib.reload(dsprep)\n",
    "import helpers; importlib.reload(helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data:\n",
    "if getpass.getuser()==\"joanna.luberadzka\":\n",
    "    INFO_FILE = projectdir + \"irstats_ARNIandBUT_datura.csv\"\n",
    "elif getpass.getuser()==\"ubuntu\":\n",
    "    INFO_FILE = projectdir+\"irstats_ARNIandBUT_datura.csv\"\n",
    "\n",
    "SAMPLING_RATE=8e3\n",
    "# instantiate data set \n",
    "dataset = dsprep.DatasetRirs(INFO_FILE,SAMPLING_RATE,preproc=\"powspec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load trained model and plot example:\n",
    "\n",
    "# ----------- Option 1 : Waveform-to-waveform variational autoencoder with linear layers only ------------\n",
    "model=models.AutoencoderConv(z_len=24).to(\"cpu\")\n",
    "model.load_state_dict(torch.load(projectdir + \"models/trained_model_08-02-2023--12-37.pth\",map_location=\"cpu\"))\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encoding: Using a trained autoencoder model, \n",
    "# generate a lower-dimensional embedding for each impulse response.\n",
    "\n",
    "embeddings_mu=[] # list for storing ir embeddings\n",
    "embeddings_rt=[] # list for storing rt values\n",
    "embeddings_drr=[] # list for storing drr values\n",
    "embeddings_isarni=[] # list for storing bool indicating which database\n",
    "embeddings_edt=[] # list for storing edt vallues\n",
    "embeddings_cte=[] # list for storing cte values\n",
    "\n",
    "# take 100 random irs from the data set\n",
    "ir_rand_indices=random.sample(range(len(dataset)),100)\n",
    "\n",
    "for i in ir_rand_indices:\n",
    "    # get info of an impulse response with a specific index\n",
    "    ir, labels= dataset[i]\n",
    "    # encode the input into mu and sigma (standard in VAE)\n",
    "    mu = model.encoder(ir)\n",
    "    # mu is the embedding (sigma provides additional info about the uncertainty of this embedding)   \n",
    "    emb = mu.squeeze() \n",
    "    # convert to numpy array and append the list of embeddings\n",
    "    embeddings_mu.append(emb.detach().cpu().numpy())\n",
    "    embeddings_rt.append(labels[\"rt\"])\n",
    "    embeddings_drr.append(labels[\"drr\"])\n",
    "    embeddings_edt.append(labels[\"edt\"])\n",
    "    embeddings_cte.append(labels[\"cte\"])\n",
    "    embeddings_isarni.append(labels[\"isarni\"])\n",
    "\n",
    "# covert from list of arrays to one array\n",
    "embeddings_mu=np.array(embeddings_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization: To visualize each encoding, the 24-dimensional embeddings \n",
    "# have to be reduced to 2 dimensions. This can be done with two methods: \n",
    "# PCA (linear) or TSNE (non-linear)\n",
    "embeddings_pca=PCA(n_components=2).fit_transform(embeddings_mu)\n",
    "embeddings_tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30).fit_transform(embeddings_mu)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1],c=embeddings_rt)\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(embeddings_pca[:,0] , embeddings_pca[:,1],c=embeddings_drr)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot (2,3,1)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=embeddings_rt)\n",
    "plt.title('color: rt')\n",
    "plt.subplot (2,3,2)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=embeddings_drr)\n",
    "plt.title('color: drr')\n",
    "plt.subplot (2,3,3)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=embeddings_edt)\n",
    "plt.title('color: edt')\n",
    "plt.subplot (2,3,4)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=embeddings_cte)\n",
    "plt.title('color: cte')\n",
    "plt.subplot (2,3,5)\n",
    "plt.scatter(embeddings_tsne[:,0] , embeddings_tsne[:,1], c=embeddings_isarni)\n",
    "plt.title('color: isarni')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction: decoder part - choose a sample from the dataset, reconstruct it and \n",
    "# check how good is the reconstruction\n",
    "\n",
    "rand_ir_idx=np.random.randint(len(dataset))\n",
    "# get info of an impulse response with a random index\n",
    "IR_orig, labels= dataset[rand_ir_idx]\n",
    "# encode the input into mu and sigma (standard in VAE)\n",
    "IR_recon, mu =model(IR_orig) \n",
    "IR_recon=IR_recon.detach().squeeze(1) \n",
    "\n",
    "# plot model reconstruction\n",
    "helpers.plot_spectrogram(IR_orig,title=\"original\", ylabel=\"freq_bin\")\n",
    "helpers.plot_spectrogram(IR_recon,title=\"reconstruction\",ylabel=\"freq_bin\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time domain reconstruction: since the model operates on magnitude spectrogram - I have to transform to \n",
    "# time domain\n",
    "\n",
    "IrData = pd.read_csv(INFO_FILE,delimiter=',')\n",
    "ir_orig_plot, S, minmax=helpers.wav2powspec(IrData[\"filepath\"][int(rand_ir_idx)], n_fft=1024, hop_length=128, win_length = 256, sample_rate = 8e3, pad_dur=3)\n",
    "ir_recons_plot=helpers.powspec2wave(IR_recon,orig_min=minmax[\"min\"],orig_max=minmax[\"max\"])\n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.subplot (1,2,1)\n",
    "plt.plot(ir_orig_plot)\n",
    "plt.title(f'Original RIR sample {rand_ir_idx}')\n",
    "plt.subplot (1,2,2)\n",
    "plt.plot(ir_recons_plot)\n",
    "plt.title(f'Reconstructed RIR sample {rand_ir_idx}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: sound on "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce963d0b11d3bbec7fb5cbe3b3e5eb22455c53ff6b457d89286ef32149820fa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
